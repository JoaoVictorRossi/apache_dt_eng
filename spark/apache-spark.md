# Apache Spark
Framework para computação distribuida voltado para processamento de Big Data, considerada uma das principais ferramentas para a área de dados.
- **Processamento em Memória:** Grava os dados que estão sendo processados na memória RAM para melhoria de desempenho.
- **Diversas Linguagens:** Possui APIs de desenvolvimento para diversas linguagens (Python, Scala, Java e R).
- **Modelo RDD:** Permite operações distribuídas com poucas linhas de código.
1. [PySpark](./spark_python/pyspark.md)
